{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Data Wrangling\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import tables\n",
    "import flammkuchen as fl\n",
    "\n",
    "# Computation\n",
    "from scipy.interpolate import interp1d\n",
    "from datetime import datetime\n",
    "import math\n",
    "import itertools\n",
    "from scipy.signal.signaltools import correlate\n",
    "import pickle\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Megabouts:\n",
    "from megabouts.pipeline.cfg import ConfigTrajPreprocess,ConfigTailPreprocess,ConfigTailSegmentation,ConfigClassification\n",
    "#Megabouts pipeline \n",
    "from megabouts.pipeline.full_tracking import PipelineFullTracking,PipelineFullTracking_Result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    TODO: check for usages of functions and clean -> maybe add more functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# my own utils\n",
    "from utils_motato import compute_angle_between_vect_tail,compute_angle_between_vect,exptrapolate_segments\n",
    "from utils_motato import tail_angles, eye_preprocess,fin_preprocess\n",
    "from utils_motato import reduce_to_pi, resample_behavior, match_times, reconstruct\n",
    "from utils_motato import cluster_colors, clust_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractuion_helpers import nanzscore\n",
    "from preprocess_helpers import reduce_to_pi\n",
    "from preprocess_helpers import rolling_window\n",
    "from preprocess_helpers import mid_head, midpoint\n",
    "from preprocess_helpers import compute_tailsum, clean_tail, tail_angles\n",
    "from preprocess_helpers import fin_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# master_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\230307_visstim_2D\")\n",
    "#master_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\231106_drunk_fish\\Control\")\n",
    "#master_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\231106_drunk_fish\\Drunk\\test\")\n",
    "# master_path = Path(r\"Z:\\Kata\\230307_visstim_2D\")\n",
    "master_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\221209_DLC_set3\")\n",
    "fish_paths = list(master_path.glob('*f[0-9]*'))\n",
    "fish_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//portulab.synology.me/data/Kata/21042024_data/221209_DLC_set3_')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\21042024_data\\230307_visstim_2D_\")\n",
    "# out_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\21042024_data\\231106_drunk_fish_control\")\n",
    "# out_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\21042024_data\\231106_drunk_fish_\")\n",
    "out_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\21042024_data\\221209_DLC_set3_\")\n",
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 videos found\n"
     ]
    }
   ],
   "source": [
    "print (\"{} videos found\".format(len(fish_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up params that dont change \n",
    "fps_new = 200\n",
    "fps = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup pipeline once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46710, 10, 49)\n",
      "TimeStep:40,OriginalPeakLoc:9,TargetPeak:8\n",
      "augmentation_delays:[-4 -3 -2 -1  0  1  2  3]\n",
      "IdSt:5\n",
      "IdSt:4\n",
      "IdSt:3\n",
      "IdSt:2\n",
      "IdSt:1\n",
      "IdSt:0\n",
      "IdSt:-1\n",
      "IdSt:-2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg_tail_preprocess = ConfigTailPreprocess(fps=fps_new,num_pcs=4,limit_na_ms=100,\n",
    "                                           baseline_method='slow',\n",
    "                                           baseline_params={'fps':700})\n",
    "\n",
    "cfg_traj_preprocess = ConfigTrajPreprocess(fps=fps_new,freq_cutoff_min=10,beta=4)\n",
    "\n",
    "\n",
    "cfg_segment = ConfigTailSegmentation(fps=fps_new,\n",
    "                                     tail_speed_filter_ms=100,tail_speed_boxcar_filter_ms=14,tail_speed_thresh_std=2.1,\n",
    "                                     min_bout_duration_ms=85,bout_duration_ms=200)\n",
    "\n",
    "cfg_classify = ConfigClassification(fps=fps_new,\n",
    "                                      margin_before_peak_ms=40,\n",
    "                                      bout_duration_ms=200,\n",
    "                                      augment_min_delay_ms=-20,\n",
    "                                      augment_max_delay_ms=20,\n",
    "                                      augment_step_delay_ms=4,\n",
    "                                      feature_weight= np.array([1.6]*7+[0,0,1]),\n",
    "                                      N_kNN=10\n",
    "                                      )\n",
    "\n",
    "pipeline = PipelineFullTracking(cfg_tail_preprocess,\n",
    "                                cfg_traj_preprocess,\n",
    "                                cfg_segment,\n",
    "                                cfg_classify,\n",
    "                                load_training=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run single fish megabouts and pool with other data\n",
    "\n",
    "    TODO: take out thresh\n",
    "    TODO: put actual templates matched in and not general library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m N_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m fish \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m fish_path \u001b[38;5;241m=\u001b[39m \u001b[43mfish_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfish\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m fish_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(fish_path)\n\u001b[0;32m      6\u001b[0m fish_path\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "N_seg = 10\n",
    "\n",
    "fish =0\n",
    "fish_path = fish_paths[fish]\n",
    "fish_id = os.path.basename(fish_path)\n",
    "fish_path\n",
    "print ('working on :', fish_path, fish_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.28525 minutes at 200 fps\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_angle_between_vect_tail' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m new_tail_x, new_tail_y \u001b[38;5;241m=\u001b[39m clean_tail(tail_x, tail_y, rolling\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  wnd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     15\u001b[0m tail_x_10, tail_y_10 \u001b[38;5;241m=\u001b[39m exptrapolate_segments(new_tail_x, new_tail_y, N_seg)\n\u001b[1;32m---> 17\u001b[0m tail_angle, body_angle \u001b[38;5;241m=\u001b[39m \u001b[43mtail_angles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtail_x_10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtail_y_10\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_seg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m tailsum \u001b[38;5;241m=\u001b[39m compute_tailsum(tail_angle)\n",
      "File \u001b[1;32m~\\python_code\\DLC_megabouts\\notebook\\data_extraction\\preprocess_helpers.py:105\u001b[0m, in \u001b[0;36mtail_angles\u001b[1;34m(tail_x_10, tail_y_10, body_x, body_y, N_seg)\u001b[0m\n\u001b[0;32m    102\u001b[0m start_vect \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((tail_x_10[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m-\u001b[39mbody_x,tail_y_10[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m-\u001b[39mbody_y))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_seg):\n\u001b[1;32m--> 105\u001b[0m     relative_angle[:,i] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_angle_between_vect_tail\u001b[49m(start_vect,vect_segment[:,:,i]\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;66;03m#,vect_segment[:,:,i+1].T)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     start_vect \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(vect_segment[:,:,i]\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    108\u001b[0m tail_angle\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mcumsum(relative_angle,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_angle_between_vect_tail' is not defined"
     ]
    }
   ],
   "source": [
    "filename = list(fish_path.glob('*316000.h5*'))[0]\n",
    "df= pd.read_hdf(filename,  header=[1, 2], index_col=0)\n",
    "df = df['DLC_resnet50_dlc_2Dec12shuffle1_316000']\n",
    "print(f'{df.shape[0]/(fps*60)} minutes at {fps} fps')\n",
    "\n",
    "#Extract angles\n",
    "body_x = df.body.values[:, 0].astype('float')\n",
    "body_y = df.body.values[:, 1].astype('float')\n",
    "tail_x_col = [f'tail_{i}' for i in range(5)]\n",
    "tail_y_col = [f'tail_{i}' for i in range(5)]\n",
    "tail_x = np.array([df[x].iloc[:, 0].values.astype('float') for x in tail_x_col])\n",
    "tail_y = np.array([df[x].iloc[:, 1].values.astype('float') for x in tail_y_col])\n",
    "\n",
    "new_tail_x, new_tail_y = clean_tail(tail_x, tail_y, rolling=False,  wnd=5, thresh=100)\n",
    "tail_x_10, tail_y_10 = exptrapolate_segments(new_tail_x, new_tail_y, N_seg)\n",
    "\n",
    "tail_angle, body_angle = tail_angles(tail_x_10, tail_y_10, body_x, body_y, N_seg)\n",
    "tailsum = compute_tailsum(tail_angle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fins\n",
    "mid_headx, mid_heady = mid_head(df)\n",
    "left_fin_vect, right_fin_vect, left_fin_angle, right_fin_angle = fin_preprocess(df, body_angle, mid_headx, mid_heady, tail_x_10, tail_y_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eye stuff\n",
    "eye_angles = fl.load(fish_path/'eye_angles.h5')['eye_angles'] #for the hdf5 way of saving dict needs ['eye_angles']\n",
    "vergence = fl.load(fish_path/'eye_rot.h5')['eye_rot']\n",
    "rotation_eye = fl.load(fish_path/'eye_verg.h5')['eye_verg']\n",
    "eye_coords = fl.load(fish_path/'eye_coords.h5')['eye_coords']\n",
    "\n",
    "left_eye_angle = np.rad2deg(eye_angles[:,0])\n",
    "right_eye_angle = np.rad2deg(eye_angles[:,1])\n",
    "rotation_eye = np.rad2deg(rotation_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Tail and Trajectory\n",
      "Segmentation\n",
      "Classification\n"
     ]
    }
   ],
   "source": [
    "#Run pipeline object\n",
    "x,y = np.zeros_like(body_angle),np.zeros_like(body_angle)\n",
    "res = pipeline.run(tail_angle,x,y,body_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get only real templates\n",
    "id_nearest_template = res.classification.id_nearest_template_aligned\n",
    "tail_templates = pipeline.knn_training_dataset_augmented.tail\n",
    "tails_nearest = tail_templates[id_nearest_template]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save results per fish\n",
    "res_dict = {'fish_id': fish_id,\n",
    "        'body_angle': np.asarray(body_angle),\n",
    "        'tail_angle': np.asarray(tail_angle),\n",
    "        'eye_angles': np.asarray([left_eye_angle, right_eye_angle]), \n",
    "        'vergence': np.asarray(vergence),\n",
    "        'rotation': np.asarray(rotation_eye), \n",
    "        'fin_angles': np.asarray([left_fin_angle, right_fin_angle]),\n",
    "        'eye_coords': np.asarray(eye_coords),\n",
    "\n",
    "        'templates_labels': pipeline.knn_training_dataset_augmented.labels, \n",
    "        'tail_and_traj_array' : res.tail_and_traj_array,\n",
    "        'bout_category' : res.classification.bout_category,\n",
    "        'bout_category_ts': res.bout_category_ts,\n",
    "        'proba' : res.classification.proba,\n",
    "        'outlier' : res.classification.outlier_score,\n",
    "        'tail_speed' : res.smooth_tail_speed,\n",
    "        'onset_shift': res.classification.onset_shift,\n",
    "        'segments_on': np.asarray(res.segments.onset),\n",
    "        'segments_off': np.asarray(res.segments.offset),\n",
    "        'id_nearest_template' : res.classification.id_nearest_template_aligned,\n",
    "        'tails_nearest' : tail_templates[id_nearest_template],\n",
    "        'clean_data_tail': res.tracking_data_clean.tail_angle, \n",
    "       }\n",
    "\n",
    "\n",
    "hf = h5py.File(out_path /'{}_megabouts_res.h5'.format(fish_id), 'w')\n",
    "dict_group = hf.create_group('data')\n",
    "for k, v in res_dict.items():\n",
    "    dict_group[k] = v\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Save tail template array once\n",
    "\n",
    "# tail_templates = pipeline.knn_training_dataset_augmented.tail\n",
    "\n",
    "# hf = h5py.File(out_path_path_path /'tail_templates.h5', 'w')\n",
    "# dict_group = hf.create_group('templates')\n",
    "# for k, v in res_dict.items():\n",
    "#     dict_group[k] = v\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path =  Path(r\"\\\\portulab.synology.me\\data\\Kata\\Processed_Data\\12052024_visstim_round_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f0'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f1'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f10'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f11'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f2'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f3'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f4'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f5'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f6'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f7'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f8'),\n",
       " WindowsPath('//portulab.synology.me/data/Kata/Data/12052024_visstim_round/240512_f9')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_path = Path(r\"\\\\portulab.synology.me\\data\\Kata\\Data\\12052024_visstim_round\")\n",
    "fish_paths = list(master_path.glob('*f[0-9]*'))\n",
    "fish_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on : \\\\portulab.synology.me\\data\\Kata\\Data\\12052024_visstim_round\\240512_f0 240512_f0\n",
      "7.802333333333333 minutes at 200 fps\n",
      "corr fins\n",
      "Preprocessing Tail and Trajectory\n",
      "Segmentation\n",
      "Classification\n"
     ]
    }
   ],
   "source": [
    "N_seg = 10\n",
    "\n",
    "\n",
    "for ind, fish_path in enumerate(tqdm(fish_paths)):\n",
    "    fish_id = os.path.basename(fish_path)\n",
    "    print ('working on :', fish_path, fish_id)\n",
    "\n",
    "    filename = list(fish_path.glob('*316000.h5*'))[0]\n",
    "    df= pd.read_hdf(filename,  header=[1, 2], index_col=0)\n",
    "    df = df['DLC_resnet50_dlc_2Dec12shuffle1_316000']\n",
    "    print(f'{df.shape[0]/(fps*60)} minutes at {fps} fps')\n",
    "    \n",
    "    #Extract angles\n",
    "    body_x = df.body.values[:, 0].astype('float')\n",
    "    body_y = df.body.values[:, 1].astype('float')\n",
    "    tail_x_col = [f'tail_{i}' for i in range(5)]\n",
    "    tail_y_col = [f'tail_{i}' for i in range(5)]\n",
    "    tail_x = np.array([df[x].iloc[:, 0].values.astype('float') for x in tail_x_col])\n",
    "    tail_y = np.array([df[x].iloc[:, 1].values.astype('float') for x in tail_y_col])\n",
    "    \n",
    "    new_tail_x, new_tail_y = clean_tail(tail_x, tail_y, rolling=False,  wnd=5, thresh=100)\n",
    "    tail_x_10, tail_y_10 = exptrapolate_segments(new_tail_x, new_tail_y, N_seg)\n",
    "    \n",
    "    tail_angle, body_angle = tail_angles(tail_x_10, tail_y_10, body_x, body_y, N_seg)\n",
    "    tailsum = compute_tailsum(tail_angle)\n",
    "\n",
    "    # calculate fins\n",
    "    mid_headx, mid_heady = mid_head(df)\n",
    "    left_fin_vect, right_fin_vect, left_fin_angle, right_fin_angle = fin_preprocess(df, body_angle, mid_headx, mid_heady, tail_x_10, tail_y_10)\n",
    "\n",
    "    # Load eye stuff\n",
    "    eye_angles = fl.load(fish_path/'eye_angles.h5')['eye_angles'] #for the hdf5 way of saving dict needs ['eye_angles']\n",
    "    vergence = fl.load(fish_path/'eye_rot.h5')['eye_rot']\n",
    "    rotation_eye = fl.load(fish_path/'eye_verg.h5')['eye_verg']\n",
    "    eye_coords = fl.load(fish_path/'eye_coords.h5')['eye_coords']\n",
    "    \n",
    "    left_eye_angle = np.rad2deg(eye_angles[:,0])\n",
    "    right_eye_angle = np.rad2deg(eye_angles[:,1])\n",
    "    rotation_eye = np.rad2deg(rotation_eye)\n",
    "\n",
    "    # Run pipeline object\n",
    "    x,y = np.zeros_like(body_angle),np.zeros_like(body_angle)\n",
    "    res = pipeline.run(tail_angle,x,y,body_angle)\n",
    "\n",
    "    #  get only real templates\n",
    "    id_nearest_template = res.classification.id_nearest_template_aligned\n",
    "    tail_templates = pipeline.knn_training_dataset_augmented.tail\n",
    "    tails_nearest = tail_templates[id_nearest_template]\n",
    "    \n",
    "    #save results per fish\n",
    "    res_dict = {'fish_id': fish_id,\n",
    "            'body_angle': np.asarray(body_angle),\n",
    "            'tail_angle': np.asarray(tail_angle),\n",
    "            'eye_angles': np.asarray([left_eye_angle, right_eye_angle]), \n",
    "            'vergence': np.asarray(vergence),\n",
    "            'rotation': np.asarray(rotation_eye), \n",
    "            'fin_angles': np.asarray([left_fin_angle, right_fin_angle]),\n",
    "            'eye_coords': np.asarray(eye_coords),\n",
    "    \n",
    "            'templates_labels': pipeline.knn_training_dataset_augmented.labels, \n",
    "            'tail_and_traj_array' : res.tail_and_traj_array,\n",
    "            'bout_category' : res.classification.bout_category,\n",
    "            'bout_category_ts': res.bout_category_ts,\n",
    "            'proba' : res.classification.proba,\n",
    "            'outlier' : res.classification.outlier_score,\n",
    "            'tail_speed' : res.smooth_tail_speed,\n",
    "            'onset_shift': res.classification.onset_shift,\n",
    "            'segments_on': np.asarray(res.segments.onset),\n",
    "            'segments_off': np.asarray(res.segments.offset),\n",
    "            'id_nearest_template' : res.classification.id_nearest_template_aligned,\n",
    "            'tails_nearest' : np.asarray(tails_nearest),\n",
    "            'clean_data_tail': res.tracking_data_clean.tail_angle, \n",
    "           }\n",
    "    \n",
    "    \n",
    "    hf = h5py.File(out_path /'{}_megabouts_res.h5'.format(fish_id), 'w')\n",
    "    dict_group = hf.create_group('data')\n",
    "    for k, v in res_dict.items():\n",
    "        dict_group[k] = v\n",
    "    hf.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "945ab21136d100d39eb08c79ef7fc552f9de38f223a833a821377820191bf364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
